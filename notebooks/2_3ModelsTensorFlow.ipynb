{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQAhRX7dv6Zn"
      },
      "source": [
        "# Models (TensorFlow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiEysN58v6Z3"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PomAMUYR-ScO"
      },
      "outputs": [],
      "source": [
        "# TFAutoModel API allows you to instantiate a pretrained model from any checkpoint.\n",
        "from transformers import TFAutoModel\n",
        "\n",
        "bert_model = TFAutoModel.from_pretrained(\"bert-base-cased\")\n",
        "print(type(bert_model))\n",
        "\n",
        "gpt_model = TFAutoModel.from_pretrained(\"gpt2\")\n",
        "print(type(gpt_model))\n",
        "\n",
        "bart_model = TFAutoModel.from_pretrained(\"facebook/bart-base\")\n",
        "print(type(bart_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alWQQK-wXVrD"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "bert_config = BertConfig.from_pretrained(\"bert-base-cased\")\n",
        "print(type(bert_config))\n",
        "\n",
        "from transformers import GPT2Config\n",
        "\n",
        "gpt_config = GPT2Config.from_pretrained(\"gpt2\")\n",
        "print(type(gpt_config))\n",
        "\n",
        "from transformers import BartConfig\n",
        "\n",
        "bart_config = BartConfig.from_pretrained(\"facebook/bart-base\")\n",
        "print(type(bart_config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo1CEk0Gb6Uq"
      },
      "outputs": [],
      "source": [
        "# Same architecture as bert-base-cased\n",
        "from transformers import BertConfig, TFBertModel\n",
        "\n",
        "bert_config = BertConfig.from_pretrained(\"bert-base-cased\")\n",
        "bert_model = TFBertModel(bert_config)\n",
        "\n",
        "# Using only 10 layers instead of 12\n",
        "from transformers import BertConfig, TFBertModel\n",
        "\n",
        "bert_config = BertConfig.from_pretrained(\"bert-base-cased\", num_hidden_layers=10)\n",
        "bert_model = TFBertModel(bert_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZtLTUgJdJNb"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, TFBertModel\n",
        "\n",
        "bert_config = BertConfig.from_pretrained(\"bert-base-cased\")\n",
        "bert_model = TFBertModel(bert_config)\n",
        "\n",
        "# Training code\n",
        "bert_model.save_pretrained(\"my-bert-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anjUF2T3dJ0F"
      },
      "outputs": [],
      "source": [
        "from transformers import TFBertModel\n",
        "\n",
        "bert_model = TFBertModel.from_pretrained(\"my-bert-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvtDtb7BnXsE"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, TFBertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HC07kA--v6aB"
      },
      "outputs": [],
      "source": [
        "# to initialize a BERT model is load a configuration object\n",
        "\n",
        "# Building the config\n",
        "config = BertConfig()\n",
        "\n",
        "# Building the model from the config\n",
        "model = TFBertModel(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w49W5w0Kv6aE",
        "outputId": "91b81bd0-d05b-4c03-e6d1-a57e7a287fe3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  [...]\n",
              "  \"hidden_size\": 768,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  [...]\n",
              "}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# hidden_size attribute defines the size of the hidden_states vector, and num_hidden_layers defines the number of layers the Transformer model has.\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV1ssaFOv6aK"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, TFBertModel\n",
        "\n",
        "config = BertConfig()\n",
        "model = TFBertModel(config)\n",
        "\n",
        "# Model is randomly initialized if created from the default configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Zz1DndDv6aN"
      },
      "outputs": [],
      "source": [
        "from transformers import TFBertModel\n",
        "\n",
        "# reuse already trained models using from_pretrained() method\n",
        "model = TFBertModel.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gc9tQKflv6aQ"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"directory_on_my_computer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMeMnjhUv6aT"
      },
      "outputs": [],
      "source": [
        "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgvoNeb6v6aW"
      },
      "outputs": [],
      "source": [
        "encoded_sequences = [\n",
        "    [101, 7592, 999, 102],\n",
        "    [101, 4658, 1012, 102],\n",
        "    [101, 3835, 999, 102],\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1Fgtt9mv6aZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model_inputs = tf.constant(encoded_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfLna6Qpv6aa"
      },
      "outputs": [],
      "source": [
        "output = model(model_inputs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
